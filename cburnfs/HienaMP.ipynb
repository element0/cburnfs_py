{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hiena Multipass Parser\n",
    "\n",
    "    hiena_mp()\n",
    "\n",
    "A Hiena parser takes a Grammar and a Target, and generates a Dictionary tree.\n",
    "\n",
    "    def hiena_mp(grammar, target, rulename) -> dict:\n",
    "        ...\n",
    "\n",
    "`hiena_mp()` is a multi-pass recursive-descent implementation suitable for small files with limited depth.\n",
    "\n",
    "## Command Interpreter Mode\n",
    "\n",
    "The 'hiena' parser can be specified as a command interpreter by putting a '#!' on the first line of the grammar file -and/or- in case the grammar is cached, a '#!' item in the grammar dict.\n",
    "\n",
    "    { \"#!\": [hienapath, opts], \n",
    "       ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from Dcel import Dcel\n",
    "\n",
    "class HienaStr(str):\n",
    "    def __create__(self,string,rematchobj,match_index):\n",
    "        super.__create__(string)\n",
    "        \n",
    "    def __init__(self,string,rematchobj,match_index):\n",
    "        self.hiena_data_start = rematchobj.start(match_index)\n",
    "        self.hiena_data_end = rematchobj.end(match_index)\n",
    "        super.__init__(string)\n",
    "\n",
    "def hiena_mp(g:dict, text:Dcel, rulename=\"$__start__\"):\n",
    "    \n",
    "    assert(type(text) is Dcel)\n",
    "    \n",
    "    # This begins its life as a list()\n",
    "    # it collects the matches for a repeating grammar rule.\n",
    "    \n",
    "    tree = list()\n",
    "    \n",
    "    # Parse a layer of `text` using current `rulename` from grammar `g`.\n",
    "    \n",
    "    if rulename in g:\n",
    "        \n",
    "        # Hook for beginning of parsing a grammar.\n",
    "        # The function is recursive, so the any rule could\n",
    "        # be a start rule if the function is\n",
    "        # called programmatically. When APath uses HienaMP\n",
    "        # as a executable interpreter, it expects $__start__. \n",
    "        \n",
    "        if rulename==\"$__start__\":\n",
    "            rulename=g[\"$__start__\"]\n",
    "        \n",
    "        # If $__start__ was not specified, this is the rulename\n",
    "        # called in the function args. Otherwise, it is the rulename\n",
    "        # resolved from $__start__.\n",
    "        \n",
    "        rule = g[rulename]\n",
    "        \n",
    "        # all matches within `text`.\n",
    "        \n",
    "        m = re.finditer(rule[0], \n",
    "                        str(text),\n",
    "                        re.M\n",
    "                       )\n",
    "        \n",
    "        # next rule that parses each match in `m`.\n",
    "        nextrulename = rule[1]\n",
    "        \n",
    "        # branch rule\n",
    "        if nextrulename != \"\":\n",
    "            for ea in m:\n",
    "                \n",
    "                # create fragment Dcel from `text`\n",
    "                map_fragment = text[ea.start(0):ea.end(0)]\n",
    "                \n",
    "                # parse match and collect result in list\n",
    "                tree.append(hiena_mp(\n",
    "                      g,\n",
    "                      # ea.group(0),    # old string version\n",
    "                      map_fragment,     # new Dcel fragment version\n",
    "                      nextrulename\n",
    "                     ))\n",
    "        \n",
    "        # terminal rule\n",
    "        else:\n",
    "            for ea in m:\n",
    "                # terminal_value = ea.group(0)  # old string version\n",
    "                map_fragment = text[ea.start(0):ea.end(0)]  # new Dcel fragment version\n",
    "                \n",
    "                # WIP: need to attach data_map to terminal_value object\n",
    "                # ie. HienaValue(ea.group(valno),ea.start(valno),ea.end(valno))\n",
    "                # ie. terminal_value.data_map = data_map\n",
    "                \n",
    "                # tree.append(terminal_value) \n",
    "                tree.append(map_fragment)\n",
    "                \n",
    "        # After all matches have been recursively parsed\n",
    "        # create a dictionary keyed by `labels` provided in field 2\n",
    "        # of the grammar rule.\n",
    "        \n",
    "        # If the `labels` are a dictionary {key:number,value:number}\n",
    "        # then, extract the label from the text of the match.\n",
    "        \n",
    "        # FIXME: validate presence of 'key' and 'value' before entering this block.\n",
    "        labels = rule[2]\n",
    "        if type(labels) == dict:\n",
    "            keyno = labels['key']\n",
    "            valno = labels['value']\n",
    "            # FIXME: eleminate this double-run of the grammar\n",
    "            # by caching the results earlier in the function.\n",
    "            m = re.finditer(rule[0], \n",
    "                    str(text),\n",
    "                    re.M\n",
    "                   )\n",
    "            \n",
    "            # HACK to populate empty Key-val-pairs with something useful.\n",
    "            # This should propogate back to the underlier correctly.\n",
    "            if(ea.start(valno) == -1):\n",
    "                valno = keyno\n",
    "            # end HACK\n",
    "            tree = { ea.group(keyno):text[ea.start(valno):ea.end(valno)]\n",
    "                    # WIP: need to attach data_map to terminal_value object\n",
    "                    # ie. HienaValue(ea.group(valno),ea.start(valno),ea.end(valno))\n",
    "                    for ea in m\n",
    "                   }\n",
    "            # WIP: need to attach a data_map to the tree\n",
    "            # ie. tree.data_map\n",
    "            return tree\n",
    "        else:        \n",
    "            tree = { k:v for k,v \n",
    "                    in zip(labels, \n",
    "                           tree\n",
    "                          )}\n",
    "        return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "{'1': {'spec': {'one': <Dcel.Dcel object at 0x7f8678653df0>, 'two': <Dcel.Dcel object at 0x7f8678634ca0>}, 'file': {'three': <Dcel.Dcel object at 0x7f8678653a90>}, 'vfstype': {'four': <Dcel.Dcel object at 0x7f8678634fd0>}}, '2': {'spec': {'five': <Dcel.Dcel object at 0x7f8678634c40>}, 'file': {'six': <Dcel.Dcel object at 0x7f8678634c10>}, 'vfstype': {'seven': <Dcel.Dcel object at 0x7f86786349a0>}, 'mntopts': {'eight': <Dcel.Dcel object at 0x7f8678634bb0>}, 'freq': {'23': <Dcel.Dcel object at 0x7f8678654460>}, 'passno': {'4': <Dcel.Dcel object at 0x7f8678654dc0>}}}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "LINE = '^.+$'\n",
    "WORD = '[^ ]+'\n",
    "CHAR = '\\w'\n",
    "entryschema = [str(i) for i in range(1,10)]\n",
    "fieldschema = [\n",
    "    'spec', 'file', 'vfstype', \n",
    "    'mntopts', 'freq', 'passno'\n",
    "]\n",
    "KVP = '([^= ,]+)(?:[=]([^=,]+))?'\n",
    "kvpschema = {'key':1,'value':2}\n",
    "fstabg = {\n",
    "    \"$__start__\": \"entry\",\n",
    "    \"entry\": [LINE, \"field\", entryschema ],\n",
    "    \"field\": [WORD, \"keyvaluepair\", fieldschema],\n",
    "    \"keyvaluepair\": [KVP, \"\", kvpschema]\n",
    "}\n",
    "\n",
    "sample = Dcel(\"\"\"\n",
    "one=1,two=2 three four\n",
    "five six seven eight 23 4\n",
    "\"\"\")\n",
    "\n",
    "x = hiena_mp(fstabg,sample)\n",
    "print(type(x))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(x['1']['spec']['one'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['1']['spec']['one'].value = \"uno\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"1\": {\"spec\": {\"one\": \"uno\", \"two\": \"2\"}, \"file\": {\"three\": \"three\"}, \"vfstype\": {\"four\": \"four\"}}, \"2\": {\"spec\": {\"five\": \"five\"}, \"file\": {\"six\": \"six\"}, \"vfstype\": {\"seven\": \"seven\"}, \"mntopts\": {\"eight\": \"eight\"}, \"freq\": {\"23\": \"23\"}, \"passno\": {\"4\": \"4\"}}}'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from DcelJSONEncoder import DcelJSONEncoder\n",
    "\n",
    "json.dumps(x,cls=DcelJSONEncoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "one=uno,two=2 three four\n",
      "five six seven eight 23 4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'three'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mtype\u001b[39m(\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfile\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mthree\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m      2\u001b[0m d \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthree\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      3\u001b[0m e \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvfstype\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfour\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'three'"
     ]
    }
   ],
   "source": [
    "type(x['1']['file']['three'])\n",
    "d = x['1']['file']['three']\n",
    "e = x['1']['vfstype']['four']\n",
    "d.value = \"surprise\"\n",
    "e.value = \"party\"\n",
    "print(f\"d: value: {d.value}, address: {d.address}, service: {d.service}\")\n",
    "json.dumps(x,cls=DcelJSONEncoder)\n",
    "\n",
    "print(sample)\n",
    "# WARNING: after running this, the internal map becomes out-of-sync.\n",
    "# The sample will need to be reparsed and will break the bindings\n",
    "# to whatever key-value-pairs have changed in the sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "str() argument 2 must be str, not re.Match",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m m \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mmatch(data)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(m\u001b[38;5;241m.\u001b[39mend(\u001b[38;5;241m0\u001b[39m))\n\u001b[0;32m----> 9\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mHienaStr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: str() argument 2 must be str, not re.Match"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "data = '1234'\n",
    "p = re.compile('1234')\n",
    "m = p.match(data)\n",
    "\n",
    "print(m.end(0))\n",
    "\n",
    "x = HienaStr(m[0],m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'one': 'uno'}\n",
      "{'one': (0, 3, {'char': (1, 1, None)})}\n",
      "{'char': (1, 1, None)}\n"
     ]
    }
   ],
   "source": [
    "# playground to practice attaching meta-data to a dict() object\n",
    "\n",
    "from collections import namedtuple\n",
    "Frag = namedtuple('Frag',['start','len','frags'])\n",
    "\n",
    "class parsetree(dict):\n",
    "    def __init__(self,datadict=dict(),fragmap=dict()):\n",
    "        self.update(datadict)\n",
    "        self.cbfrag = fragmap\n",
    "        \n",
    "tree = parsetree({\"one\":\"uno\"},{\"one\":(0,3,{\"char\":(1,1,None)})})\n",
    "\n",
    "print(tree)\n",
    "print(tree.cbfrag)\n",
    "print(tree.cbfrag['one'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = { 'key': 1 }\n",
    "\n",
    "d['key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (402375693.py, line 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/private/var/mobile/Containers/Data/Application/93EC6E1D-567D-45D0-B634-138E1BDF830E/tmp/ipykernel_16726/402375693.py\"\u001b[0;36m, line \u001b[0;32m12\u001b[0m\n\u001b[0;31m    if a.value === a.value:\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from Dcel import Dcel\n",
    "from DictFS import DictFS\n",
    "\n",
    "fstab = Dcel(address=fstabg, \n",
    "               service_class=DictFS\n",
    "              )\n",
    "\n",
    "a = Dcel(formula=hiena_mp, \n",
    "         args=[fstab,sample]\n",
    "        )\n",
    "\n",
    "if a.value is a.value:\n",
    "    print('same')\n",
    "    \n",
    "a.value['1']['one'] = 'uno'\n",
    "\n",
    "b = Dcel(address=a, \n",
    "         service_class=DictFS\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "print(b)\n",
    "\n",
    "for ea in b.listdir():\n",
    "    try:\n",
    "        print(ea)\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "q = Dcel()\n",
    "r = Dcel()\n",
    "s = Dcel({'q':q,'r':r},service_class=DictFS)\n",
    "for ea in s.listdir():\n",
    "    print(s[ea])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:8: SyntaxWarning: list indices must be integers or slices, not tuple; perhaps you missed a comma?\n",
      "<>:8: SyntaxWarning: list indices must be integers or slices, not tuple; perhaps you missed a comma?\n",
      "/private/var/mobile/Containers/Data/Application/93EC6E1D-567D-45D0-B634-138E1BDF830E/tmp/ipykernel_721/1818053981.py:8: SyntaxWarning: list indices must be integers or slices, not tuple; perhaps you missed a comma?\n",
      "  field = [[word,flags]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/tmp/ipykernel_721/1818053981.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m field = [[word,flags]\n\u001b[0m\u001b[1;32m      9\u001b[0m     ['spec', \n\u001b[1;32m     10\u001b[0m      \u001b[0;34m'file'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "line = '^.+$'\n",
    "word = '\\w+'\n",
    "flags = re.M\n",
    "\n",
    "entry = [[word,flags],[1,2],dict()]\n",
    "field = [[word,flags]\n",
    "    ['spec', \n",
    "     'file', \n",
    "     'vfstype', \n",
    "     'mntopts',\n",
    "     'freq',\n",
    "     'passno'], \n",
    "     {'freq':'[0-9]+', \n",
    "      'passno':'[0-9]+'\n",
    "     }\n",
    "]\n",
    "\n",
    "sample = \"\"\"\n",
    "one two three four 1 0\n",
    "five six seven eight 23 4\n",
    "\"\"\"\n",
    "\n",
    "def parse(g, text):\n",
    "    lex = g[0][0]\n",
    "    fl  = g[0][1] \n",
    "    labels = g[1]\n",
    "    sublex = g[2]\n",
    "    m = re.findall(lex,text,flags)\n",
    "    w = { k:v for k,v in zip(labels,m)}\n",
    "    print(w)\n",
    "    for ea in sublex:\n",
    "        if ea in w:\n",
    "            print(re.match(sublex[ea],w[ea],0))\n",
    "\n",
    "parse(entry, sample)\n",
    "parse(field, sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in 1-10:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "ruleref_re = re.compile(\"(?P<surface_id>[/@]?)(?P<rule_id>[^{} ]+)(?P<qty>[{][*][}])?\")\n",
    "\n",
    "class HienaParser:\n",
    "    def __init__(self, \n",
    "                 target=None,\n",
    "                 grammar=None,\n",
    "                ):\n",
    "        self.target = target\n",
    "        self.grammar = grammar\n",
    "    \n",
    "    def run_lex(self, \n",
    "                text:str,\n",
    "                regex_args:list,\n",
    "                ) -> list:\n",
    "        if not type(regex_args) is list:\n",
    "            raise TypeError('Requires a list of args suitable for re.findall()')\n",
    "        _re = regex_args[0]\n",
    "        try:\n",
    "            _flags = regex_args[1]\n",
    "        except:\n",
    "            _flags = 0\n",
    "        return re.findall(_re, text, _flags)\n",
    "        \n",
    "    def parse_rule_reference(self,ref):\n",
    "        m = re.match(ruleref_re,ref,0)\n",
    "        surfaceid = ''\n",
    "        args = [ ref ]\n",
    "        return (surfaceid,args)\n",
    "        \n",
    "    def run_rule(self, \n",
    "                 target:str = None,\n",
    "                 rulename:str = \"\",\n",
    "                 quantity:str = \"*\",\n",
    "                ):\n",
    "        rulepart = self.grammar[rulename]\n",
    "        print('rulepart: '+rulepart)\n",
    "        # for first element\n",
    "        i = 0\n",
    "        try:\n",
    "            self.run_lex(rulepart[0])\n",
    "            i += 1\n",
    "        except:\n",
    "            pass  \n",
    "\n",
    "        def process_rulebody(e):\n",
    "            try:\n",
    "                a = self.parse_rule_reference(e)\n",
    "                res = self.run_rule(*a[1])\n",
    "            except:\n",
    "                raise\n",
    "                \n",
    "        if type(rulepart) is str:\n",
    "            process_rulebody(rulepart)\n",
    "            \n",
    "        if type(rulepart) is list:\n",
    "            # loop over rulebody\n",
    "            for e in rulepart[i:]:\n",
    "                print(e)\n",
    "                process_rulebody(e)\n",
    "        \n",
    "    def run(self):\n",
    "        startname = self.grammar[\"$__start__\"]\n",
    "        return self.run_rule(self.target, \n",
    "                             rulename=startname\n",
    "                          )\n",
    "                        \n",
    "def hiena1(target: str, grammar: dict) -> (map, dict):\n",
    "    mapp = { k: re.findall(grammar[k],\n",
    "                 target)\n",
    "            for k in grammar }\n",
    "    dirr = None\n",
    "    return (mapp,dirr)\n",
    "\n",
    "def hiena(target: str, grammar: dict) -> (map, dict):\n",
    "    parser = HienaParser(target,grammar)\n",
    "    return parser.run()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "surface_id = \"(?P<surface_id>[/@]?)\"\n",
    "rule_id = \"(?P<rule_id>[^{}+*? ]+)\"\n",
    "qty = \"(?P<qty>[+*?]|(?:[{][1-9]+[}]))?\"\n",
    "carver = \"([{][^{}]*[}])\"\n",
    "carvers = \"(?:\\W*\"+carver+\")+\"\n",
    "_=\"\\W*\"+carver\n",
    "ruleref = surface_id+rule_id+qty+carvers\n",
    "quantifier = \"([*])|([1-9])|([^*, ]+)\"\n",
    "ruleref_re = re.compile(ruleref)\n",
    "quantifier_re = re.compile(quantifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "fstabGrammar = {\n",
    "    \"$__start__\": \"fstab\",\n",
    "    \"fstab\": [ \"/entry+\" ],\n",
    "    \"entry\": [ \"ENTRY{2}\"\n",
    "               \"{@field+:spec,file,vfstype,mntopts,freq:digit,passno:digit} {other} {such}\" ], \n",
    "    \"ENTRY\": [[r\"^[^#\\n]+\", re.M]],\n",
    "    \"field\": [[r\"[^# ]+\"]],\n",
    "    \"digit\": [[r\"[0-9]\"]], \n",
    "    \n",
    "    \" \" : \" \"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fstabGrammar['entry'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = re.search( \n",
    "    ruleref_re,\n",
    "    fstabGrammar['entry'][0], \n",
    "    0 \n",
    ")\n",
    "print(a.groups())\n",
    "\n",
    "b = re.findall( \n",
    "    carver,\n",
    "    fstabGrammar['entry'][0], \n",
    "    0 \n",
    ")\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fs.osfs import OSFS\n",
    "from Dcel import Dcel\n",
    "\n",
    "d = Dcel(address='fs', \n",
    "         service_class=OSFS\n",
    "        )\n",
    "text = d.path_lookup('.cosm/etc/fstab').value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "s = '/entry{*}'\n",
    "print(s[0])\n",
    "print(s[1:].split('{')[1][0])\n",
    "print()\n",
    "\n",
    "strings = [ '/entry{*}', \n",
    "           '/entry',\n",
    "           'entry{*}',\n",
    "           'entry'\n",
    "          ]\n",
    "\n",
    "import re\n",
    "for s in strings:\n",
    "    c = re.compile(\"(?P<surface_id>[/@]?)(?P<rule_id>[^{} ]+)(?P<qty>[{][*][}])?\")\n",
    "    m = re.match(c,s,0)\n",
    "    print(m.groupdict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = hiena(text,fstabGrammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grammar = {\"word\": r\"[^ ]+\"}\n",
    "hiena(\"one two three\", grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = {'fs_entry': r\"(.+)\\n\"}\n",
    "d = \"\"\"\n",
    "sftp://example.com  /  sftpfs\n",
    "\n",
    "localhost:/example  /  file\n",
    "\n",
    "files.example.com   /  webdavfs\n",
    "\"\"\"\n",
    "hiena(d,g)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
