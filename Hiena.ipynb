{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hiena Multipass Parser\n",
    "\n",
    "    hiena_mp()\n",
    "\n",
    "The Hiena parser takes a Grammar and a Target, and generates a Dictionary tree.\n",
    "\n",
    "    def hiena_mp(grammar, target, rulenam) -> dict:\n",
    "        ...\n",
    "\n",
    "The **target** can be a string, stream or (map, dict) pair.\n",
    "\n",
    "## Multi-pass Parser\n",
    "\n",
    "A multi-pass recursive-descent implementation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"spec\": \"one\", \"file\": \"two\", \"vfstype\": \"three\", \"mntopts\": \"four\"}, {\"spec\": \"five\", \"file\": \"six\", \"vfstype\": \"seven\", \"mntopts\": \"eight\", \"freq\": \"23\", \"passno\": \"4\"}]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "LINE = '^.+$'\n",
    "WORD = '\\w+'\n",
    "CHAR = '\\w'\n",
    "fieldschema = [\n",
    "    'spec', 'file', 'vfstype', \n",
    "    'mntopts', 'freq', 'passno'\n",
    "]\n",
    "fstabg = {\n",
    "    \"entry\": [LINE, \"field\" ],\n",
    "    \"field\": [WORD, \"\", fieldschema],\n",
    "    \"char\":  [CHAR, \"\"]\n",
    "}\n",
    "\n",
    "\n",
    "def hiena_mp(g, text,rulename):\n",
    "    schema = list()\n",
    "    tree = list()\n",
    "    if rulename in g:\n",
    "        rule = g[rulename]\n",
    "        m = re.finditer(rule[0], \n",
    "                        text,\n",
    "                        re.M\n",
    "                       )\n",
    "        try:\n",
    "            schema = rule[2]\n",
    "        except:\n",
    "            pass\n",
    "        nextrulename = rule[1]\n",
    "        if nextrulename != \"\":\n",
    "            for ea in m:\n",
    "                tree.append(hiena_mp(\n",
    "                      g, \n",
    "                      ea.group(0), \n",
    "                      nextrulename\n",
    "                     ))\n",
    "        else:\n",
    "            for ea in m:\n",
    "                tree.append(ea.group(0))\n",
    "        try:\n",
    "            labels = rule[2]\n",
    "        except:\n",
    "            return tree\n",
    "        \n",
    "        tree = { k:v for k,v \n",
    "                in zip(labels, \n",
    "                       tree\n",
    "                      )}\n",
    "        return tree\n",
    "\n",
    "sample = \"\"\"\n",
    "one two three four\n",
    "five six seven eight 23 4\n",
    "\"\"\"\n",
    "        \n",
    "x = hiena_mp(fstabg,sample,\"entry\")\n",
    "print(json.dumps(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 36]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [ x+1 for x in (1,2,36)]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:8: SyntaxWarning: list indices must be integers or slices, not tuple; perhaps you missed a comma?\n",
      "<>:8: SyntaxWarning: list indices must be integers or slices, not tuple; perhaps you missed a comma?\n",
      "<ipython-input-2-9445ab052cd4>:8: SyntaxWarning: list indices must be integers or slices, not tuple; perhaps you missed a comma?\n",
      "  field = [[word,flags]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-9445ab052cd4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m field = [[word,flags]\n\u001b[0m\u001b[1;32m      9\u001b[0m     ['spec', \n\u001b[1;32m     10\u001b[0m      \u001b[0;34m'file'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "line = '^.+$'\n",
    "word = '\\w+'\n",
    "flags = re.M\n",
    "\n",
    "entry = [[word,flags],[1,2],dict()]\n",
    "field = [[word,flags]\n",
    "    ['spec', \n",
    "     'file', \n",
    "     'vfstype', \n",
    "     'mntopts',\n",
    "     'freq',\n",
    "     'passno'], \n",
    "     {'freq':'[0-9]+', \n",
    "      'passno':'[0-9]+'\n",
    "     }\n",
    "]\n",
    "\n",
    "sample = \"\"\"\n",
    "one two three four 1 0\n",
    "five six seven eight 23 4\n",
    "\"\"\"\n",
    "\n",
    "def parse(g, text):\n",
    "    lex = g[0][0]\n",
    "    fl  = g[0][1] \n",
    "    labels = g[1]\n",
    "    sublex = g[2]\n",
    "    m = re.findall(lex,text,flags)\n",
    "    w = { k:v for k,v in zip(labels,m)}\n",
    "    print(w)\n",
    "    for ea in sublex:\n",
    "        if ea in w:\n",
    "            print(re.match(sublex[ea],w[ea],0))\n",
    "\n",
    "parse(entry, sample)\n",
    "parse(field, sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-9-d3561bc18e6e>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-d3561bc18e6e>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    for i in 1:10:\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "for i in 1-10:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "ruleref_re = re.compile(\"(?P<surface_id>[/@]?)(?P<rule_id>[^{} ]+)(?P<qty>[{][*][}])?\")\n",
    "\n",
    "class HienaParser:\n",
    "    def __init__(self, \n",
    "                 target=None,\n",
    "                 grammar=None,\n",
    "                ):\n",
    "        self.target = target\n",
    "        self.grammar = grammar\n",
    "    \n",
    "    def run_lex(self, \n",
    "                text:str,\n",
    "                regex_args:list,\n",
    "                ) -> list:\n",
    "        if not type(regex_args) is list:\n",
    "            raise TypeError('Requires a list of args suitable for re.findall()')\n",
    "        _re = regex_args[0]\n",
    "        try:\n",
    "            _flags = regex_args[1]\n",
    "        except:\n",
    "            _flags = 0\n",
    "        return re.findall(_re, text, _flags)\n",
    "        \n",
    "    def parse_rule_reference(self,ref):\n",
    "        m = re.match(ruleref_re,ref,0)\n",
    "        surfaceid = ''\n",
    "        args = [ ref ]\n",
    "        return (surfaceid,args)\n",
    "        \n",
    "    def run_rule(self, \n",
    "                 target:str = None,\n",
    "                 rulename:str = \"\",\n",
    "                 quantity:str = \"*\",\n",
    "                ):\n",
    "        rulepart = self.grammar[rulename]\n",
    "        print('rulepart: '+rulepart)\n",
    "        # for first element\n",
    "        i = 0\n",
    "        try:\n",
    "            self.run_lex(rulepart[0])\n",
    "            i += 1\n",
    "        except:\n",
    "            pass  \n",
    "\n",
    "        def process_rulebody(e):\n",
    "            try:\n",
    "                a = self.parse_rule_reference(e)\n",
    "                res = self.run_rule(*a[1])\n",
    "            except:\n",
    "                raise\n",
    "                \n",
    "        if type(rulepart) is str:\n",
    "            process_rulebody(rulepart)\n",
    "            \n",
    "        if type(rulepart) is list:\n",
    "            # loop over rulebody\n",
    "            for e in rulepart[i:]:\n",
    "                print(e)\n",
    "                process_rulebody(e)\n",
    "        \n",
    "    def run(self):\n",
    "        startname = self.grammar[\"$__start__\"]\n",
    "        return self.run_rule(self.target, \n",
    "                             rulename=startname\n",
    "                          )\n",
    "                        \n",
    "def hiena1(target: str, grammar: dict) -> (map, dict):\n",
    "    mapp = { k: re.findall(grammar[k],\n",
    "                 target)\n",
    "            for k in grammar }\n",
    "    dirr = None\n",
    "    return (mapp,dirr)\n",
    "\n",
    "def hiena(target: str, grammar: dict) -> (map, dict):\n",
    "    parser = HienaParser(target,grammar)\n",
    "    return parser.run()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "surface_id = \"(?P<surface_id>[/@]?)\"\n",
    "rule_id = \"(?P<rule_id>[^{}+*? ]+)\"\n",
    "qty = \"(?P<qty>[+*?]|(?:[{][1-9]+[}]))?\"\n",
    "carver = \"([{][^{}]*[}])\"\n",
    "carvers = \"(?:\\W*\"+carver+\")+\"\n",
    "_=\"\\W*\"+carver\n",
    "ruleref = surface_id+rule_id+qty+carvers\n",
    "quantifier = \"([*])|([1-9])|([^*, ]+)\"\n",
    "ruleref_re = re.compile(ruleref)\n",
    "quantifier_re = re.compile(quantifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "fstabGrammar = {\n",
    "    \"$__start__\": \"fstab\",\n",
    "    \"fstab\": [ \"/entry+\" ],\n",
    "    \"entry\": [ \"ENTRY{2}\"\n",
    "               \"{@field+:spec,file,vfstype,mntopts,freq:digit,passno:digit} {other} {such}\" ], \n",
    "    \"ENTRY\": [[r\"^[^#\\n]+\", re.M]],\n",
    "    \"field\": [[r\"[^# ]+\"]],\n",
    "    \"digit\": [[r\"[0-9]\"]], \n",
    "    \n",
    "    \" \" : \" \"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENTRY{@field+:spec,file,vfstype,mntopts,freq:digit,passno:digit} {other} {such}\n"
     ]
    }
   ],
   "source": [
    "print(fstabGrammar['entry'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('', 'ENTRY', '{2}', '{such}')\n",
      "[('', 'ENTRY', '{2}', '{such}')]\n"
     ]
    }
   ],
   "source": [
    "a = re.search( \n",
    "    ruleref_re,\n",
    "    fstabGrammar['entry'][0], \n",
    "    0 \n",
    ")\n",
    "print(a.groups())\n",
    "\n",
    "b = re.findall( \n",
    "    carver,\n",
    "    fstabGrammar['entry'][0], \n",
    "    0 \n",
    ")\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fs.osfs import OSFS\n",
    "from Dcel import Dcel\n",
    "\n",
    "d = Dcel(address='fs', \n",
    "         service_class=OSFS\n",
    "        )\n",
    "text = d.path_lookup('.cosm/etc/fstab').value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "s = '/entry{*}'\n",
    "print(s[0])\n",
    "print(s[1:].split('{')[1][0])\n",
    "print()\n",
    "\n",
    "strings = [ '/entry{*}', \n",
    "           '/entry',\n",
    "           'entry{*}',\n",
    "           'entry'\n",
    "          ]\n",
    "\n",
    "import re\n",
    "for s in strings:\n",
    "    c = re.compile(\"(?P<surface_id>[/@]?)(?P<rule_id>[^{} ]+)(?P<qty>[{][*][}])?\")\n",
    "    m = re.match(c,s,0)\n",
    "    print(m.groupdict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = hiena(text,fstabGrammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grammar = {\"word\": r\"[^ ]+\"}\n",
    "hiena(\"one two three\", grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = {'fs_entry': r\"(.+)\\n\"}\n",
    "d = \"\"\"\n",
    "sftp://example.com  /  sftpfs\n",
    "\n",
    "localhost:/example  /  file\n",
    "\n",
    "files.example.com   /  webdavfs\n",
    "\"\"\"\n",
    "hiena(d,g)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
